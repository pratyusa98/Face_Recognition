{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "2befe5df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing the libraries\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.applications.mobilenet_v2 import MobileNetV2\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "a5710f92",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 21 images belonging to 3 classes.\n"
     ]
    }
   ],
   "source": [
    "#data sugmentation\n",
    "# Preprocessing the Training set\n",
    "datagen = ImageDataGenerator(rescale=1./255,validation_split=0.30,\n",
    "                            rotation_range=40,\n",
    "                            width_shift_range=0.2,\n",
    "                            height_shift_range=0.2,\n",
    "                            shear_range=0.2,\n",
    "                            zoom_range=0.2,\n",
    "                            horizontal_flip=True,\n",
    "                            fill_mode='nearest')\n",
    "training_set = datagen.flow_from_directory('Dataset',\n",
    "                                                    target_size=(224,224),\n",
    "                                                    color_mode=\"rgb\",\n",
    "                                                    subset=\"training\",\n",
    "                                                    class_mode=\"binary\",\n",
    "                                                    batch_size=32,\n",
    "                                                    shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "73beb34d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 9 images belonging to 3 classes.\n"
     ]
    }
   ],
   "source": [
    "valid_set=datagen.flow_from_directory(directory=\"Dataset\",\n",
    "                                    target_size=(224,224),\n",
    "                                    color_mode=\"rgb\",\n",
    "                                    subset=\"validation\",\n",
    "                                    class_mode=\"binary\",\n",
    "                                    batch_size=32,\n",
    "                                    shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "33f75aac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from glob import glob\n",
    "folders = glob('Dataset/*')\n",
    "len(folders)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "b5b6afeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# \n",
    "# def plotImages(images_arr):\n",
    "#     fig, axes = plt.subplots(1, 5, figsize=(20, 20))\n",
    "#     axes = axes.flatten()\n",
    "#     for img, ax in zip(images_arr, axes):\n",
    "#         ax.imshow(img)\n",
    "#     plt.tight_layout()\n",
    "#     plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "0c4fe7b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# images = [training_set[0][0][0] for i in range(5)]\n",
    "# plotImages(images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "c694a84c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "3555dc30",
   "metadata": {},
   "outputs": [],
   "source": [
    "IMAGE_SIZE = [224, 224]\n",
    "mobilenet = MobileNetV2(input_shape=IMAGE_SIZE + [3], weights='imagenet', include_top=False)\n",
    "# don't train existing weights\n",
    "for layer in mobilenet.layers:\n",
    "  layer.trainable = False\n",
    "\n",
    "# our layers - you can add more if you want\n",
    "x = Flatten()(mobilenet.output)\n",
    "# x = Dense(1000, activation='relu')(x)\n",
    "prediction = Dense(len(folders), activation='softmax')(x)\n",
    "\n",
    "# create a model object\n",
    "model = Model(inputs=mobilenet.input, outputs=prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "381463cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tell the model what cost and optimization method to use\n",
    "model.compile( loss='sparse_categorical_crossentropy', optimizer='adam',metrics=['accuracy'] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "d2098287",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "1/1 [==============================] - 3s 3s/step - loss: 0.6529 - accuracy: 0.9048 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 2/5\n",
      "1/1 [==============================] - 3s 3s/step - loss: 1.7598e-07 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 3/5\n",
      "1/1 [==============================] - 3s 3s/step - loss: 0.0108 - accuracy: 1.0000 - val_loss: 8.8744e-07 - val_accuracy: 1.0000\n",
      "Epoch 4/5\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 5.1656e-06 - val_accuracy: 1.0000\n",
      "Epoch 5/5\n",
      "1/1 [==============================] - 2s 2s/step - loss: 4.3168e-05 - accuracy: 1.0000 - val_loss: 2.2581e-05 - val_accuracy: 1.0000\n"
     ]
    }
   ],
   "source": [
    "# fit the model\n",
    "r = model.fit( training_set,\n",
    "  validation_data=valid_set,\n",
    "  epochs=5,\n",
    "    batch_size=16\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "68fb168c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 2s 2s/step\n"
     ]
    }
   ],
   "source": [
    "pred1=np.argmax(model.predict(valid_set,verbose=1),axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "307e5b9d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'modi': 0, 'pratyusa': 1, 'trump': 2}"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "valid_set.class_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "4821c40b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: my_model.json\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\python37\\lib\\site-packages\\keras\\engine\\functional.py:1410: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n",
      "  layer_config = serialize_layer_fn(layer)\n",
      "c:\\python37\\lib\\site-packages\\keras\\saving\\saved_model\\layer_serialization.py:112: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n",
      "  return generic_utils.serialize_keras_object(obj)\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "model.save('my_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "eafd73d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "model_att = load_model('my_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "8dbc97d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Modi\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from tensorflow.keras.preprocessing import image\n",
    "test_image = image.load_img('pratyusa.jpg', target_size = (224,224))\n",
    "test_image = image.img_to_array(test_image)\n",
    "test_image=test_image/255\n",
    "test_image = np.expand_dims(test_image, axis = 0)\n",
    "result = model_att.predict(test_image)\n",
    "result = np.argmax(result)\n",
    "result\n",
    "if result==0:\n",
    "    print(\"Modi\")\n",
    "elif result == 1:\n",
    "    print('Pratyusa')\n",
    "elif result == 2:\n",
    "    print('Trump')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c16732e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
